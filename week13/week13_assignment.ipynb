{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc1c39d0d6f8b82a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Descriptive Stats\n",
    "\n",
    "For the questions below, we're going to refer exclusively to an HHCAPS survey data set that is available in `/data/hhcaps.csv`.  Use whatever commands you want to calculate the information required to get to the answer.\n",
    "\n",
    "\n",
    "Put your solution as the last line right before the test cell, using the form shown below for computing the number of rows in a dataframe.\n",
    "\n",
    "```\n",
    "answer = my_df.shape[0]\n",
    "```\n",
    "\n",
    "The assertions will often give you what the final answer should be, but you won't receive any points unless you compute the answer using code.  For instance, if you just typed `answer = 132` for the numer of rows instead of `answer = my_df.shape[0]`, you would not receive credit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "hhcaps = pd.read_csv('/data/hhcaps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #01 - \n",
    "\n",
    "How many columns does this file contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 39)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhcaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = hhcaps.shape[1]\n",
    "## Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q01-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == int)\n",
    "assert(answer == 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #02 - \n",
    "\n",
    "How many different values for State are there in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = hhcaps['State'].nunique()\n",
    "## Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q02-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == int)\n",
    "assert(answer == 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #03 - \n",
    "\n",
    "Which of those State values has the highest frequency of occurence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = hhcaps['State'].value_counts().index[0]\n",
    "## Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q03-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == str)\n",
    "assert(answer == 'TX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #04 - \n",
    "\n",
    "Which of those State values has the best average performance on the `Star Rating for health team communicated well with them` score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = hhcaps.groupby(['State']).agg({'Star Rating for health team communicated well with them':'mean'}).reset_index().sort_values('Star Rating for health team communicated well with them', ascending=False).head(1)['State'].values[0]\n",
    "## Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q04-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == str)\n",
    "assert(answer == 'ME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q05-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #05 - \n",
    "\n",
    "What was the average score on `Star Rating for how patients rated overall care from agency` for providers listed as having a `Type of Ownership` of `Hospital Based Program`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q05-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "f5 = hhcaps[hhcaps['Type of Ownership']=='Hospital Based Program']\n",
    "answer = f5['Star Rating for how patients rated overall care from agency'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q05-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "assert(type(answer) == float or type(answer) == numpy.float64)\n",
    "assert(round(answer,5) == round(3.6925207756232687,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q06-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #06 - \n",
    "\n",
    "There is one column in the file that has the same value on every row.  What is the name of that column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q06-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "cols = hhcaps.columns\n",
    "for col in cols:\n",
    "    if hhcaps[col].nunique() == 1:\n",
    "        answer = col    \n",
    "## Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q06-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == str)\n",
    "assert(answer.lower() == 'Offers Nursing Care Services'.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q07-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #07 - \n",
    "\n",
    "There are six (6) columns in the file that indicate (True or False) if the provider offers certain services.  Those column names all start with `Offers...`.  How many facilities offer **everything** that the survey was interested in asking about?  That is, how many rows have True in all six of those columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q07-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = 0\n",
    "cols = hhcaps.columns\n",
    "offer_cols=[]\n",
    "for col in cols:\n",
    "    if 'Offers' in col:\n",
    "        offer_cols.append(col)\n",
    "df_7 = hhcaps[offer_cols]\n",
    "for index, row in df_7.iterrows():\n",
    "    counter = 0\n",
    "    for i in row:\n",
    "        if i == True:\n",
    "            counter=counter+1\n",
    "    if counter == 6:\n",
    "        answer = answer+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q07-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == int)\n",
    "assert(answer == 9029)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q08-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #08 - \n",
    "\n",
    "The survey results report `Number of completed Surveys` as one of the metrics.  What is the `median` of the number of completed surveys per facility?\n",
    "\n",
    "Note that some rows don't have a valid number in them for the number of completed surveys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hhcaps['Number of completed Surveys']=hhcaps['Number of completed Surveys'].replace('Not Available', 0)\n",
    "df_8 = hhcaps[hhcaps['Number of completed Surveys']!='Not Available']\n",
    "answer = df_8['Number of completed Surveys'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q08-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == float or type(answer) == numpy.float64)\n",
    "assert(answer == 84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q09-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #09 - \n",
    "\n",
    "How many providers are there from St. Louis, Missouri?\n",
    "\n",
    "*Note that the City columnd may have trailing spaces that need to be accomodated or cleaned up*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9 = hhcaps[hhcaps['State'] == 'MO']\n",
    "df_9_2 = pd.DataFrame(hhcaps['City'].value_counts()).reset_index()\n",
    "df_9_2['index']=df_9_2['index'].map(lambda x: x.strip())\n",
    "answer = int(df_9_2[df_9_2['index']== 'SAINT LOUIS']['City'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q09-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == int)\n",
    "assert(answer == 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q10-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# #10 - \n",
    "\n",
    "Which state got the highest percentage of 'top box' scorings, using the `Percent of patients who gave their home health agency a rating of 9 or 10 on a scale from 0 (lowest) to 10 (highest)` field.\n",
    "\n",
    "Ignore those rows where the data is **Not Available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_10(a):\n",
    "    sum = 0\n",
    "    for i in a:\n",
    "        sum = sum + int(i)\n",
    "    return (sum/len(a))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = 0\n",
    "field = 'Percent of patients who gave their home health agency a rating of 9 or 10 on a scale from 0 (lowest) to 10 (highest)'\n",
    "df_10 = hhcaps[hhcaps[field] != 'Not Available']\n",
    "states =df_10['State'].unique()\n",
    "answer_10 = {}\n",
    "for state in states:\n",
    "    df_state = df_10[df_10['State'] == state]\n",
    "    vals = df_state[field].values\n",
    "    #top = df_state[field].max()\n",
    "    #answer_10 [state] = len(df_state[df_state[field] == top])   \n",
    "    answer_10[state] = fun_10(vals)\n",
    "answer = sorted(answer_10, key=answer_10.get)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q10-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == str)\n",
    "assert(answer == 'MS')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
